{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f8fd143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\mereu\\miniconda3\\lib\\site-packages (0.49.1)\n",
      "Requirement already satisfied: lime in c:\\users\\mereu\\miniconda3\\lib\\site-packages (0.2.0.1)\n",
      "Requirement already satisfied: ollama in c:\\users\\mereu\\miniconda3\\lib\\site-packages (0.6.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\mereu\\miniconda3\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from shap) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from shap) (1.7.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from shap) (2.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from shap) (4.67.1)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from shap) (25.0)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba>=0.54 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from shap) (0.62.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from shap) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from shap) (4.15.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from lime) (3.9.2)\n",
      "Requirement already satisfied: scikit-image>=0.12 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from lime) (0.25.2)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from ollama) (0.27.2)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from ollama) (2.10.5)\n",
      "Requirement already satisfied: anyio in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from httpx>=0.27->ollama) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from httpx>=0.27->ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from httpx>=0.27->ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from httpx>=0.27->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from numba>=0.54->shap) (0.45.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (2.27.2)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (3.2.1)\n",
      "Requirement already satisfied: pillow>=10.1 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (10.4.0)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (2025.6.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from scikit-learn->shap) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from scikit-learn->shap) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from matplotlib->lime) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from matplotlib->lime) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from matplotlib->lime) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from matplotlib->lime) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from matplotlib->lime) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from matplotlib->lime) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mereu\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install shap lime ollama python-dotenv\n",
    "#!pip install \"numpy==1.26.4\" --force-reinstall\n",
    "#!pip install \"shap<0.50\" lime ollama python-dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae9ba4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# DacÄƒ rulezi notebook-ul din folderul demo/, cwd = .../xai-nlg-framework/demo\n",
    "# Deci root-ul proiectului e un nivel mai sus:\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if ROOT_DIR not in sys.path:\n",
    "    sys.path.append(ROOT_DIR)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import src.pipeline\n",
    "importlib.reload(src.pipeline)\n",
    "\n",
    "from config.settings import FrameworkConfig\n",
    "from src.pipeline import XAINLGPipeline\n",
    "from src.nlg.few_shot_generator import FewShotGenerator\n",
    "from src.nlg.ollama_client import ollama_llm_call\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6321235e",
   "metadata": {},
   "source": [
    "dataset + model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ce06dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 114, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "feature_names = list(data.feature_names)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Config + pipeline\n",
    "config = FrameworkConfig(verbose = True)\n",
    "config.explainer.top_k_features = 5 \n",
    "pipeline = XAINLGPipeline(\n",
    "    model,\n",
    "    X_train,\n",
    "    feature_names,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "\n",
    "len(X_train), len(X_test), len(feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33979e7",
   "metadata": {},
   "source": [
    "pipeline + explicaÈ›ie SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e8b7bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.utils:[x] Layer 1: Generating explanations\n",
      "INFO:src.utils:  method: shap\n",
      "INFO:src.utils:[x] Layer 2: Normalizing\n",
      "INFO:src.utils:  features: 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw prediction: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['instance', 'method', 'explanation', 'base_value', 'prediction', 'ranked_features', 'statements'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alegem o instanÈ›Äƒ de explicat\n",
    "instance = X_test[0]\n",
    "raw_pred = int(model.predict(instance.reshape(1, -1))[0])\n",
    "print(\"Raw prediction:\", raw_pred)\n",
    "\n",
    "# generÄƒm explicaÈ›ia SHAP (fÄƒrÄƒ NLG intern)\n",
    "result = pipeline.explain_instance(\n",
    "    instance,\n",
    "    method=\"shap\",\n",
    "    generate_text=False,   # NLG Ã®l facem noi Ã®n notebook\n",
    ")\n",
    "\n",
    "result.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ac5777",
   "metadata": {},
   "source": [
    "NLG cu Few-Shot + Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c8a4622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('worst area', 0.06724261426271144),\n",
       " ('worst concave points', 0.05740842121890832),\n",
       " ('mean concave points', 0.04227830540602773),\n",
       " ('worst radius', 0.03956915260512325),\n",
       " ('worst perimeter', 0.03026387093604719)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Layer 3: NLG cu Ollama (Few-Shot) ===\n",
    "\n",
    "# generator NLG care foloseÈ™te llama3:latest din Ollama\n",
    "nlg = FewShotGenerator(config.nlg, llm_call_fn=ollama_llm_call)\n",
    "\n",
    "# Top-k features din explicaÈ›ia SHAP\n",
    "top_k = result[\"ranked_features\"][: config.explainer.top_k_features]\n",
    "top_k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3884384",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directions = []\n",
    "for _, v in top_k:\n",
    "    if v > 0:\n",
    "        directions.append(\"supports\")\n",
    "    elif v < 0:\n",
    "        directions.append(\"contradicts\")\n",
    "    else:\n",
    "        directions.append(\"neutral\")\n",
    "\n",
    "raw_pred = int(result[\"prediction\"])\n",
    "\n",
    "pred_expert_en = \"malignant tumor\" if raw_pred == 0 else \"benign tumor\"\n",
    "pred_layman_en = \"high risk of breast cancer\" if raw_pred == 0 else \"low risk of breast cancer\"\n",
    "\n",
    "base_context = {\n",
    "    \"features\": [f for f, _ in top_k],\n",
    "    \"values\": [float(v) for _, v in top_k],\n",
    "    \"directions\": directions,\n",
    "    \"method\": result.get(\"method\", \"shap\"),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7e7929",
   "metadata": {},
   "source": [
    "## generÄƒm efectiv textul cu Llama3 prin Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c787c6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExplicaÈ›ie tehnicÄƒ (pentru medic sau cercetÄƒtor):\n",
      "The model predicts a benign tumor because several morphological features have small positive contributions to the malignancy score. The worst area, concave points, radius, and perimeter all exhibit low values that support the benign class, as reflected by their positive SHAP values. These dominant positive contributions outweigh any potential opposing effects and collectively push the overall prediction towards a benign outcome.\n",
      "\n",
      "Pe scurt, pentru un pacient:\n",
      "The model suggests a low risk of breast cancer because the lump's size and shape are more typical of harmless findings. The characteristics that stand out as supportive of this prediction include the lump's relatively small dimensions, which are often seen in non-cancerous cases. Overall, these features point towards a benign outcome.\n"
     ]
    }
   ],
   "source": [
    "from src.nlg.few_shot_generator import FewShotGenerator\n",
    "from src.nlg.ollama_client import ollama_llm_call\n",
    "\n",
    "# puÈ›in mai â€žcuminteâ€ pentru format fix\n",
    "config.nlg.temperature = 0.2  \n",
    "\n",
    "nlg = FewShotGenerator(config.nlg, llm_call_fn=ollama_llm_call)\n",
    "\n",
    "# 1) context pentru EXPERT\n",
    "context_expert = {\n",
    "    **base_context,\n",
    "    \"prediction\": pred_expert_en,   # ex: \"malignant tumor\" / \"benign tumor\"\n",
    "    \"audience\": \"expert\",\n",
    "}\n",
    "\n",
    "# 2) context pentru LAYMAN\n",
    "context_layman = {\n",
    "    **base_context,\n",
    "    \"prediction\": pred_layman_en,   # ex: \"high risk of breast cancer\" / \"low risk of breast cancer\"\n",
    "    \"audience\": \"layman\",\n",
    "}\n",
    "\n",
    "text_expert = nlg.generate(context_expert)\n",
    "text_layman = nlg.generate(context_layman)\n",
    "\n",
    "print(\"ExplicaÈ›ie tehnicÄƒ (pentru medic sau cercetÄƒtor):\")\n",
    "print(text_expert)\n",
    "print(\"\\nPe scurt, pentru un pacient:\")\n",
    "print(text_layman)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c6549a",
   "metadata": {},
   "source": [
    "## Chain of Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "493d7404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import get_top_k_features\n",
    "\n",
    "# ranked_features = list of (feature_name, value)\n",
    "top_k = result[\"ranked_features\"][: config.explainer.top_k_features]\n",
    "\n",
    "directions = []\n",
    "for _, v in top_k:\n",
    "    if v > 0:\n",
    "        directions.append(\"supports\")\n",
    "    elif v < 0:\n",
    "        directions.append(\"contradicts\")\n",
    "    else:\n",
    "        directions.append(\"neutral\")\n",
    "\n",
    "raw_pred = int(result[\"prediction\"])\n",
    "\n",
    "pred_expert_en = \"malignant tumor\" if raw_pred == 0 else \"benign tumor\"\n",
    "pred_layman_en = \"high risk of breast cancer\" if raw_pred == 0 else \"low risk of breast cancer\"\n",
    "\n",
    "base_context = {\n",
    "    \"features\": [f for f, _ in top_k],\n",
    "    \"values\": [float(v) for _, v in top_k],\n",
    "    \"directions\": directions,\n",
    "    \"method\": result.get(\"method\", \"shap\"),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8948765c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Chain-of-Thought (technical) ===\n",
      "The predicted outcome is that the tumor is benign. The top factors contributing to this prediction are all related to the characteristics of the worst areas and features of the tumor, including its concave points, radius, and perimeter. These factors all support the prediction of a benign tumor, indicating that the tumor's shape and size are consistent with a non-cancerous growth. Overall, the combination of these factors suggests that the tumor is likely to be benign.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Chain-of-Thought (simple) ===\n",
      "The analysis suggests that the patient is at a low risk of developing breast cancer. The key factors contributing to this outcome are the worst area, worst concave points, mean concave points, worst radius, and worst perimeter, all of which support the prediction. These features indicate that the patient's breast tissue has a more compact and uniform structure, with fewer irregularities or abnormalities that could increase the risk of cancer. Overall, the combination of these factors provides strong evidence for a low risk of breast cancer.\n"
     ]
    }
   ],
   "source": [
    "from src.nlg.cot_generator import ChainOfThoughtGenerator\n",
    "from src.nlg.ollama_client import ollama_llm_call\n",
    "\n",
    "cot_gen = ChainOfThoughtGenerator(config.nlg, llm_call_fn=ollama_llm_call)\n",
    "\n",
    "context_cot_expert = {\n",
    "    **base_context,\n",
    "    \"prediction\": pred_expert_en,\n",
    "}\n",
    "\n",
    "text_cot_expert = cot_gen.generate(context_cot_expert)\n",
    "\n",
    "print(\"=== Chain-of-Thought (technical) ===\")\n",
    "print(text_cot_expert)\n",
    "\n",
    "context_cot_layman = {\n",
    "    **base_context,\n",
    "    \"prediction\": pred_layman_en,\n",
    "}\n",
    "\n",
    "text_cot_layman = cot_gen.generate(context_cot_layman)\n",
    "\n",
    "print(\"\\n=== Chain-of-Thought (simple) ===\")\n",
    "print(text_cot_layman)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef6fe91",
   "metadata": {},
   "source": [
    "## Self_conistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bbac572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Self-Consistency (aggregated, technical) ===\n",
      "The model predicts a benign tumor based on several key factors. The worst area and worst concave points of the tumor both strongly support this prediction, indicating that the tumor's shape and size are consistent with a benign growth. Additionally, the mean concave points and worst radius also contribute to this conclusion, suggesting that the tumor's texture and overall structure are typical of a non-cancerous nature. The worst perimeter also supports this finding, implying that the tumor's boundary is not irregular or suspicious. Overall, these factors collectively suggest that the tumor is likely benign.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Self-Consistency (aggregated, simple) ===\n",
      "Based on the model's prediction of a low risk of breast cancer, the top factors that contribute to this outcome are features related to the tumor's shape and size. The presence of a \"worst area\" with a moderate value of 0.067 supports this prediction, indicating that the tumor is not overly aggressive in terms of its spatial distribution. Similarly, the \"worst concave points\", \"mean concave points\", \"worst radius\", and \"worst perimeter\" all have positive values, suggesting that the tumor's shape is not particularly irregular or abnormal, which further supports a low risk of breast cancer. Overall, these features collectively contribute to a reassuring profile for the patient.\n"
     ]
    }
   ],
   "source": [
    "from src.nlg.self_consistency_generator import SelfConsistencyGenerator\n",
    "\n",
    "sc_gen = SelfConsistencyGenerator(\n",
    "    config.nlg,\n",
    "    n_chains=3,                    # poÈ›i pune 3â€“5, dar È›ine cont de latenÈ›Äƒ\n",
    "    llm_call_fn=ollama_llm_call,\n",
    ")\n",
    "\n",
    "context_sc_expert = {\n",
    "    **base_context,\n",
    "    \"prediction\": pred_expert_en,\n",
    "}\n",
    "\n",
    "text_sc_expert = sc_gen.generate(context_sc_expert)\n",
    "\n",
    "print(\"=== Self-Consistency (aggregated, technical) ===\")\n",
    "print(text_sc_expert)\n",
    "\n",
    "context_sc_layman = {\n",
    "    **base_context,\n",
    "    \"prediction\": pred_layman_en,\n",
    "}\n",
    "\n",
    "text_sc_layman = sc_gen.generate(context_sc_layman)\n",
    "\n",
    "print(\"\\n=== Self-Consistency (aggregated, simple) ===\")\n",
    "print(text_sc_layman)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03ce6a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.utils:[x] Layer 1: Generating explanations\n",
      "INFO:src.utils:  method: shap\n",
      "INFO:src.utils:[x] Layer 2: Normalizing\n",
      "INFO:src.utils:  features: 30\n",
      "INFO:src.utils:[x] Layer 3: Generating text\n",
      "INFO:src.utils:  generator: few_shot\n",
      "INFO:src.utils:  technique: few_shot\n",
      "INFO:src.utils:  audience: expert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "TECHNIQUE = few_shot\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:src.utils:[x] Layer 4: Validating\n",
      "INFO:src.utils:[x] Layer 1: Generating explanations\n",
      "INFO:src.utils:  method: shap\n",
      "INFO:src.utils:[x] Layer 2: Normalizing\n",
      "INFO:src.utils:  features: 30\n",
      "INFO:src.utils:[x] Layer 3: Generating text\n",
      "INFO:src.utils:  generator: cot\n",
      "INFO:src.utils:  technique: cot\n",
      "INFO:src.utils:  audience: expert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reported technique: few_shot\n",
      "Reported generator: few_shot\n",
      "\n",
      "Generated text:\n",
      "\n",
      "The model predicts a positive outcome because several morphological features have small to moderate positive contributions to the overall prediction. The worst area, concave points, mean concave points, radius, and perimeter all support this classification with their positive SHAP values. These dominant positive contributions collectively push the overall prediction towards a positive outcome, with no notable opposing factors present in the top attributions.\n",
      "\n",
      "Validation: {'sum_conservation_valid': False, 'computed_sum': 0.97, 'clarity_score': 78.0}\n",
      "\n",
      "==============================\n",
      "TECHNIQUE = cot\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:src.utils:[x] Layer 4: Validating\n",
      "INFO:src.utils:[x] Layer 1: Generating explanations\n",
      "INFO:src.utils:  method: shap\n",
      "INFO:src.utils:[x] Layer 2: Normalizing\n",
      "INFO:src.utils:  features: 30\n",
      "INFO:src.utils:[x] Layer 3: Generating text\n",
      "INFO:src.utils:  generator: self_consistency\n",
      "INFO:src.utils:  technique: self_consistency\n",
      "INFO:src.utils:  audience: expert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reported technique: cot\n",
      "Reported generator: cot\n",
      "\n",
      "Generated text:\n",
      "\n",
      "The predicted outcome is that the object will be classified as \"1\". The top factors contributing to this prediction are all related to the shape and size of the object's boundary. Specifically, the worst area, concave points, radius, and perimeter all support the prediction by indicating a complex and irregular shape. These features collectively suggest that the object is not a simple or typical instance, which aligns with the predicted classification of \"1\".\n",
      "\n",
      "Validation: {'sum_conservation_valid': False, 'computed_sum': 0.97, 'clarity_score': 83.5}\n",
      "\n",
      "==============================\n",
      "TECHNIQUE = self_consistency\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:src.utils:[x] Layer 4: Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reported technique: self_consistency\n",
      "Reported generator: self_consistency\n",
      "\n",
      "Generated text:\n",
      "\n",
      "The model predicted a score of 1, indicating that this instance is likely to belong to the positive class. The SHAP values reveal that several features contribute positively to this prediction. Specifically, the presence of \"worst area\", \"worst concave points\", \"mean concave points\", \"worst radius\", and \"worst perimeter\" all support the predicted outcome. These features collectively suggest that this instance has characteristics that are typical of the positive class.\n",
      "\n",
      "Validation: {'sum_conservation_valid': False, 'computed_sum': 0.97, 'clarity_score': 85.5}\n"
     ]
    }
   ],
   "source": [
    "for tech in [\"few_shot\", \"cot\", \"self_consistency\"]:\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\"TECHNIQUE = {tech}\")\n",
    "    print(\"==============================\")\n",
    "\n",
    "    res = pipeline.explain_instance(\n",
    "        instance,\n",
    "        method=\"shap\",\n",
    "        generate_text=True,\n",
    "        technique=tech,        # ðŸ‘ˆ AICI testÄƒm ramura\n",
    "        audience=\"expert\",     # pentru few_shot; la celelalte e ignorat\n",
    "    )\n",
    "\n",
    "    print(\"Reported technique:\", res.get(\"nlg_technique\"))\n",
    "    print(\"Reported generator:\", res.get(\"nlg_generator\"))\n",
    "    print(\"\\nGenerated text:\\n\")\n",
    "    print(res.get(\"generated_text\", \"\")[:800])  # primele 800 caractere\n",
    "    print(\"\\nValidation:\", res.get(\"validation\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
